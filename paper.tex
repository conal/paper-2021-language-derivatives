\documentclass[hidelinks,12pt]{article}  % fleqn,12pt
\usepackage[margin=0.1in]{geometry}  % 0.12in, 0.9in, 1in

\usepackage{catchfilebetweentags}
\usepackage[useregional]{datetime2}

%% \usepackage{balance}  % even out final two-column page

\RequirePackage{newunicodechar, amssymb, stmaryrd, unicode-math, setspace, comment}

\input{commands}
\input{unicode}
\input{macros}

\usepackage{agda}% references

%% Switching to \textsf for AgdaFunction messes up vertical alignment.
%% \newcommand{\AgdaFontStyle}[1]{\textsf{#1}}

%% \renewcommand{\AgdaFontStyle}[1]{\text{#1}}

%% \renewcommand{\AgdaFunction}[1]
%%     {\AgdaNoSpaceMath{\text{\textcolor{AgdaFunction}{\AgdaFormat{#1}{\AgdaLink{#1}}}}}}
%% \renewcommand{\AgdaRecord}[1]
%%     {\AgdaNoSpaceMath{\text{\textcolor{AgdaRecord}{\AgdaFormat{#1}{\AgdaLink{#1}}}}}}

\author{Conal Elliott}

\begin{document}

%% \nc\tit{Working Title}
\nc\tit{%Functional Pearl:
Symbolic and Automatic Differentiation of Languages}

\title{\tit}
\date{Early draft of \DTMnow}

\maketitle

\begin{abstract}
Formal languages are usually defined in terms of set theory.
Choosing type theory instead gives us languages as type-level predicates over strings.
Applying a language to a string yields a type whose elements are language membership proofs describing \emph{how} a string parses in the language.
The usual building blocks of languages (including union, contatenation, and Kleene closure) have precise and compelling specifications uncomplicated by operational strategies and are easily generalized to a few general domain-transforming and codomain-transforming operations on predicates.

A simple type isomorphism property captures the essential idea behind language ``differentiation'' and ``integration'' as used for recognizing languages and leads to a collection of lemmas about type-level languages (and indeed functions from lists to any type).
These lemmas form the backbone of two dual implementations of language recognition---(inductive) regular expressions and (coinductive) tries---each containing the same code but in dual arrangements.
The language lemmas form most of the implementation in both cases, while the representation and primitive operations trade places.
The regular expression version corresponds to symbolic differentiation, while the trie version corresponds to automatic differentiation.

The relatively easy-to-prove properties of type-level languages transfer almost effortlessly to the decidable implementations.
In particular, despite the inductive and coinductive nature of regular expressions and tries respectively, we need neither inductive nor coinductive/bisumulation arguments to prove algebraic properties.
\end{abstract}

\rnc\AgdaTarget[1]{}

\sectionl{Specifying Languages}

\rnc\source{Language}

Languages are usually formalized either set-theoretically as a set of strings \needcite{} or operationally as a parser \needcite{}.
Alternatively, we can use type theory, so that a language is a type-level predicate on ``strings'' (lists of an arbitrary type \AB{A} of ``characters''):
\agda{Lang}
\figrefdef{Lang-ops}{Language operations}{\agda{Lang-ops}} gives definitions of the usual language operations, including language union and intersection ({\AB{P} \AF ‚à™ \AB{Q}} and {\AB{P} \AF ‚à© \AB{Q}}) with their identities (the empty language \AF ‚àÖ and universal language \AF ùí∞), language concatenation ({\AB{P} \AF ‚ãÜ \AB{Q}}) and its identity (\AF ùüè, containing only the empty string), single-character languages ({\AF ` \AB{c}}), Kleene star ({\AB{P} \AF ‚òÜ}), and ``scalar multiplication'' (\mbox{\AB{s} \AF ¬∑ \AB{P}}, which will prove useful later).

\note{Explain the types used here and their logical interpretation under the Curry-Howard isomorphism.}

Note that for a language \AB{P} and string \AB{w}, {\AB{P} \AB{w}} is the type of \emph{proofs} that {\AB{w} ‚àà \AB{P}}, in other words \emph{explanations} of membership, or \emph{parsing}.
(If the type {\AB{P} \AB{w}} is uninhabited, then {\AB{w} ‚àâ \AB{P}}.)
For instance, a proof of {\AB{w} ‚àà \AB{P} \AF ‚à™ \AB{Q}} contains a proof of {\AB{w} ‚àà \AB{P}} or of {\AB{w} \AF ‚àà \AB{Q}}, \emph{and} the knowledge of which one was chosen.
Likewise, a proof of {w ‚àà \AB{P} \AF ‚ãÜ \AB{Q}} (language concatenation) includes the choice of strings \AB{u} and \AB{v}, a proof that {\AB{u} \AF ‚äô \AB{v} \AD ‚â° \AB{w}}, and proofs that {\AB{u} ‚àà \AB{P}} and {\AB{v} ‚àà \AB{P}}.

The use of type-level predicates makes for simple, direct specification, including the use of existential quantification.
As described in \secref{Language Algebra}, it's also fairly easy to prove algebraic properties of predicates\out{, including the semimodule and semiring laws for both predicate semirings}.
These definitions do not, however, give us decidable parsing, because general type inhabitation amounts to theorem proving.

\sectionl{Decomposing Languages}

\rnc\source{Calculus}

In order to convert languages into parsers, it will help to decompose languages---and indeed any function from lists---into a regular form.
Since lists are defined by an algebraic data type, we can decompose languages according to constructor, as follows:
\agda{ŒΩŒ¥}
Each use of \AF{Œ¥} takes us one step closer to reducing general language membership to nullability.
In other words,\footnote{Repeated application is expressed as a left fold\out{ \stdlibCitep{Data.List}}:
\agda{foldl}
}%
\agda{ŒΩ‚àòfoldlŒ¥}

This simple observation is the semantic heart of the syntactic technique of \emph{derivatives of regular expressions} as used for efficient recognition of regular languages \citep{Brzozowski64}, later extended to parsing general context-free languages \citep{Might2010YaccID}.
Lemma \AF{ŒΩ‚àòfoldlŒ¥} liberates this technique from the assumption that languages are represented \emph{symbolically}, by some form of grammar (e.g., regular or context-free), inviting other representations as we will see in \secref{Automatic}.

Lemma \AF{ŒΩ‚àòfoldlŒ¥} relates to some other powerful perspectives and principles as well:
\begin{itemize}

\item 
\emph{Automata theory}: {\AF{ŒΩ} \AF ‚àò \AF{foldl} \AF{Œ¥} \AB{P}} is the execution of a state machine.
Each state is a language, with \AB{P} being the initial state; \AF{Œ¥} is the state transition function; and \AB{ŒΩ} is the set of accepting states \needcite{}.
Lemma \AF{ŒΩ‚àòfoldlŒ¥} captures the correctness of this state machine as a recognizer for the language \AB{P}.

\item
\emph{Incremental computation}: {\AF{ŒΩ} \AF ‚àò \AF{foldl} \AF{Œ¥} \AB{P}} computes \AB{P} by transforming successive incremental modifications to the empty string (each in the form of {\AB{a} \AIC ‚à∑\_} for a list element \AB{a}) into incremental modifications to the membership question for the related language {\AF{Œ¥} \AB{P} \AB{a}} \needcite{}.
Lemma \AF{ŒΩ‚àòfoldlŒ¥} again captures the correctness of this incremental implementation of \AB{P}.

\item 
\emph{Calculus}: \AB{Œ¥} is differentiation; {\AF{ŒΩ} \AF ‚àò \AF{foldl} \AF{Œ¥} \AB{P}} is integration; and lemma \AF{ŒΩ‚àòfoldlŒ¥} is the second fundamental theorem of calculus, which says that a function can be recovered by integrating its derivative \needcite{}.

\end{itemize}

Given the definitions of \AF{ŒΩ} and \AF{Œ¥} above and of the language operations in \secref{Specifying Languages}, one can prove properties about how they relate, as shown in
\figrefdef{nu-delta-lemmas}{Properties of \AF{ŒΩ} and \AF{Œ¥} for language operations}{\agda{ŒΩŒ¥-lemmas}}.
The correct-by-construction parsing algorithms in \secreftwo{Symbolic Differentiation}{Automatic Differentiation} are corollaries of these properties.

There are three relations involved in \figref{nu-delta-lemmas}: propositional equality (``‚â°''), type isomorphism (``‚Üî'') and extensional isomorphism (``‚ü∑'').
Type isomorphism relates types whose inhabitants/proofs are in one-to-one correspondence.
\emph{Extensional} (or ``pointwise'') isomorphism relates predicates isomorphic on every argument:
\agda{ext-iso}

As with all lemmas in this paper shown with signatures only, full proofs are in the paper's source code and are formally verified by the Agda compiler.
The equalities in \figref{nu-delta-lemmas} are all proved automatically by normalization (i.e., their proofs are simply \AIC{refl}), while the other relations require a bit more work.

\sectionl{Decidability}

\rnc\source{Decidability}

For an effective implementation, we will have to bridge the gap between a type (of membership proofs) and its decidable inhabitation.
Fortunately, there is a convenient and compositional way to do so.
For any type \AB{X}, the type {\AF{Dec} \AB{X}} contains proof of \AB{X} or a proof of {\AF ¬¨ \AB{X}} (defined as usual to mean {\AB{X} \AS ‚Üí \AD{‚ä•}}):\footnote{This simple \AF{Dec} definition been superceded by a more efficient but more complex version \stdlibCitep{Relation.Nullary}.}

\agda{Dec}
For compositionality, we will also want higher-order counterparts lifting decidability of types to decidability of constructions on those types:
\agda{Decs}

\bibliography{bib}

\end{document}
